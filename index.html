<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Vex Tea (Michael Lazarek) ‚Äî AI Systems Engineer | Transparent Local AI Research</title>
  <meta name="description" content="Local-first AI research framework work: interpretability, audit logging, consent-based sensing, and staged learning architectures." />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header class="header">
    <div class="container">
      <div class="topActions">
        <button class="iconBtn" id="themeToggle" aria-label="Toggle theme" title="Toggle theme">
          <span class="icon" id="themeIcon">üåô</span>
        </button>
        <button class="iconBtn" id="pdfDownload" aria-label="Download as PDF" title="Download as PDF">
          <span class="icon">üìÑ</span>
        </button>
      </div>

      <h1 class="name">Vex Tea <span class="legalName">(Michael Lazarek)</span></h1>
      <p class="tagline">AI Systems Engineer ¬∑ Transparent & Local AI Research</p>

      <nav class="contact">
        <a href="mailto:vextea@proton.me">Email</a>
        <a href="https://github.com/Cevtex" target="_blank" rel="noreferrer">GitHub</a>
        <a href="https://www.linkedin.com/in/vex-tea/" target="_blank" rel="noreferrer">LinkedIn</a>
      </nav>

      <div class="quickLinks">
        <a class="pill" href="#system-bootstrap">System Bootstrap</a>
        <a class="pill" href="#research">Research Focus</a>
        <a class="pill" href="#timeline">Iteration Timeline</a>
        <a class="pill" href="system-bootstrap.html">Project Page ‚Üí</a>
      </div>
    </div>
  </header>

  <main class="container">
    <section class="about" id="about">
      <h2>About</h2>
      <p>
        I build local-first AI systems focused on interpretability, audit logging, and architectural accountability.
        My work explores staged learning (mimic ‚Üí relate ‚Üí respond), consent-based environmental sensing, and confidence calibration
        as foundations for trust in persistent human‚ÄìAI systems.
      </p>
      <p class="muted">
        This site showcases a year-long R&amp;D line that evolved from early prototypes into <strong>System Bootstrap</strong>‚Äîa research framework designed
        to be inspectable by default (no cloud dependency required).
      </p>
    </section>

    <section class="highlight" id="system-bootstrap">
      <div class="sectionHeader">
        <h2>System Bootstrap</h2>
        <div class="sectionActions">
          <a class="btn" href="system-bootstrap.html">Read the full project page</a>
          <a class="btn btnGhost" href="https://github.com/Cevtex" target="_blank" rel="noreferrer">Code</a>
        </div>
      </div>

      <p class="meta">Python ¬∑ PySide6 ¬∑ Local-first AI research framework ¬∑ 2024‚ÄìPresent</p>

      <div class="twoCol">
        <div class="card">
          <h3>What it is</h3>
          <p>
            A local AI research framework for studying transparency and alignment-by-architecture.
            It prioritizes inspectable state over scale, and uses explicit consent gates for any environmental sensing.
          </p>
          <ul class="bullets">
            <li>Staged learning architecture (mimic ‚Üí relation ‚Üí respond)</li>
            <li>Confidence growth + context similarity (semantic + sensory)</li>
            <li>Authoritative event logging (JSONL) with replay-friendly structure</li>
            <li>In-app controls: STOP SENSORS / REVOKE CONSENT</li>
            <li>Session folder isolation to keep long runs auditable</li>
          </ul>
        </div>

        <div class="card">
          <h3>Why it matters</h3>
          <p>
            Modern AI systems often hide their decision pathways. System Bootstrap is an attempt to make internal mechanics observable:
            confidence signals, state transitions, and the exact context features used for decisions.
          </p>
          <ul class="bullets">
            <li>Interpretability-first: expose stage + confidence + matches</li>
            <li>Local-first: avoid ‚Äúphone-home‚Äù dependencies</li>
            <li>Alignment-by-design: governance is built into the architecture</li>
            <li>Research-ready: structured logs enable experiments and analysis</li>
          </ul>
        </div>
      </div>

      <div class="callout">
        <strong>Portfolio note:</strong> earlier prototypes are kept and documented as an iteration trail (below). They‚Äôre presented as R&amp;D steps
        toward a stable research framework rather than standalone ‚Äúchatbots.‚Äù
      </div>
    </section>

    <section class="skills" id="skills">
      <h2>Technical Skills</h2>
      <div class="skillGrid">
        <div class="skillCategory">
          <h3>Languages</h3>
          <ul>
            <li>Python</li>
            <li>HTML/CSS</li>
            <li>YAML / JSON</li>
            <li>Markdown</li>
          </ul>
        </div>

        <div class="skillCategory">
          <h3>Systems</h3>
          <ul>
            <li>Local-first architecture</li>
            <li>Event logging (JSONL)</li>
            <li>State persistence + session isolation</li>
            <li>Windows tooling & automation</li>
          </ul>
        </div>

        <div class="skillCategory">
          <h3>AI / Research Concepts</h3>
          <ul>
            <li>Interpretability & transparency signals</li>
            <li>Confidence accumulation & calibration</li>
            <li>Context similarity (cosine / TF-IDF / embeddings)</li>
            <li>Human-in-the-loop evaluation design</li>
          </ul>
        </div>
      </div>
    </section>

    <section class="research" id="research">
      <div class="sectionHeader">
        <h2>Research Statement</h2>
        <div class="sectionActions">
          <a class="btn btnGhost" href="system-bootstrap.html#research-statement">Deep dive</a>
        </div>
      </div>

      <div class="card">
        <p class="lead">
          I‚Äôm interested in <strong>trust and alignment in persistent AI systems</strong>, with an emphasis on
          <strong>transparency mechanisms</strong> and <strong>uncertainty calibration</strong>.
        </p>

        <h3>Working thesis</h3>
        <p>
          Alignment and trust improve when an AI system makes its internal mechanics observable: what it used as context,
          how confident it is, and why a given action or response was produced.
        </p>

        <h3>Active questions</h3>
        <ul class="bullets">
          <li>Do transparency signals (confidence + memory source + context snapshot) increase user trust?</li>
          <li>How should confidence accumulate over time in a persistent local system?</li>
          <li>What is the tradeoff between stability (constraints) and behavioral variance (exploration)?</li>
          <li>Can alignment be strengthened through architecture before large-model training is introduced?</li>
        </ul>

        <h3>Next steps</h3>
        <ul class="bullets">
          <li>Run transparency vs opaque mode studies using the same underlying engine</li>
          <li>Compute calibration curves / ECE on confidence estimates using labeled tasks</li>
          <li>Replace symbolic similarity baselines with learned embeddings and compare interpretability tradeoffs</li>
        </ul>
      </div>
    </section>

    <section class="timeline" id="timeline">
      <h2>Iteration Timeline (R&amp;D Trail)</h2>

      <div class="timelineGrid">
        <article class="timelineItem">
          <div class="kicker">Iteration 0</div>
          <h3>Thasala OS Prototype</h3>
          <p class="meta">Modular UI shell ¬∑ logging-first ¬∑ safety override patterns</p>
          <p>
            Early multi-window architecture exploring system logging, rule-based response engines, and a dedicated kernel-style
            log window. This phase established the ‚Äúaudit-first‚Äù mindset and tooling.
          </p>
          <ul class="bullets">
            <li>Multi-window framework + launcher</li>
            <li>Dedicated kernel/log console concept</li>
            <li>Early rule-based safety override heuristics</li>
          </ul>
        </article>

        <article class="timelineItem">
          <div class="kicker">Iteration 1</div>
          <h3>Hiroma (Relational Dynamics)</h3>
          <p class="meta">Bilateral incentives ¬∑ memory experiments ¬∑ interaction modeling</p>
          <p>
            A research sandbox for modeling interaction effects: incentive structures (token economy), compressed memories,
            and behavior shaping through outcomes.
          </p>
          <ul class="bullets">
            <li>Witness Coin-style incentive experiments</li>
            <li>Compressed memory abstractions</li>
            <li>Pattern-based response selection</li>
          </ul>
        </article>

        <article class="timelineItem">
          <div class="kicker">Iteration 2</div>
          <h3>System Bootstrap (Framework Line)</h3>
          <p class="meta">Consent-gated sensing ¬∑ staged learning ¬∑ replayable logs</p>
          <p>
            Consolidation into a shareable research framework: explicit consent controls, session isolation,
            and instrumented learning stages with confidence telemetry.
          </p>
          <ul class="bullets">
            <li>Permission gates + revocation</li>
            <li>Authoritative event logs (JSONL) + session folders</li>
            <li>Staged learning & confidence tracking</li>
          </ul>
        </article>

        <article class="timelineItem">
          <div class="kicker">Interface Layer</div>
          <h3>Refuteke (Symbolic Interface)</h3>
          <p class="meta">Constructed logographic language ¬∑ state depiction experiments</p>
          <p>
            A structured symbolic system used as an interface layer for experimental state depiction and naming.
            This is presented as interface research, not a dependency for System Bootstrap.
          </p>
          <ul class="bullets">
            <li>130+ rune vocabulary work</li>
            <li>Typography + tooling experiments</li>
            <li>Documentation-first iteration</li>
          </ul>
        </article>
      </div>
    </section>

    <section class="experience" id="experience">
      <h2>Experience</h2>

      <article class="job">
        <h3>Independent Computer Technician</h3>
        <p class="meta">Community Service ¬∑ 2015‚ÄìPresent</p>
        <ul class="bullets">
          <li>Hardware + OS troubleshooting across diverse machines</li>
          <li>Practical security habits and data integrity focus</li>
          <li>Clear technical explanations for non-technical users</li>
        </ul>
      </article>

      <article class="job">
        <h3>Food Service Representative</h3>
        <p class="meta">Byrne Dairy ¬∑ 2024‚ÄìPresent</p>
        <ul class="bullets">
          <li>High-throughput work under time pressure (reliability, composure, accuracy)</li>
          <li>Self-directed technical study alongside full-time schedule</li>
        </ul>
      </article>
    </section>

    <section class="education" id="education">
      <h2>Education & Learning</h2>

      <article class="educationItem">
        <h3>TripleTen Data Science Program</h3>
        <p class="meta">In progress ¬∑ 2025‚ÄìPresent</p>
        <p class="muted">
          Formalizing ML fundamentals while continuing independent research and systems engineering work.
        </p>
      </article>

      <article class="educationItem">
        <h3>Self-Directed Study</h3>
        <p class="meta">2024‚ÄìPresent</p>
        <p class="muted">
          Daily study in AI systems, interpretability, and local-first architecture, supported by iterative prototyping
          and structured documentation.
        </p>
      </article>
    </section>

    <section class="values" id="values">
      <h2>Engineering Values</h2>
      <ul class="bullets">
        <li><strong>Transparency by default:</strong> logs and state are first-class artifacts.</li>
        <li><strong>User control:</strong> permission gates and revocation are not optional.</li>
        <li><strong>Local-first:</strong> minimize cloud dependency; maximize auditability.</li>
        <li><strong>Mechanism over mystique:</strong> confidence, context, and decisions should be inspectable.</li>
      </ul>
    </section>

    <footer class="footer">
      <div class="container">
        <p>&copy; <span id="year"></span> Vex Tea ¬∑ Built with semantic HTML/CSS ¬∑ GitHub Pages</p>
      </div>
    </footer>
  </main>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
  <script>
    // Year
    document.getElementById('year').textContent = new Date().getFullYear();

    // Theme
    const html = document.documentElement;
    const themeToggle = document.getElementById('themeToggle');
    const themeIcon = document.getElementById('themeIcon');
    const stored = localStorage.getItem('theme') || 'dark';
    html.setAttribute('data-theme', stored);
    themeIcon.textContent = stored === 'dark' ? 'üåô' : '‚òÄÔ∏è';

    themeToggle.addEventListener('click', () => {
      const current = html.getAttribute('data-theme') || 'dark';
      const next = current === 'dark' ? 'light' : 'dark';
      html.setAttribute('data-theme', next);
      localStorage.setItem('theme', next);
      themeIcon.textContent = next === 'dark' ? 'üåô' : '‚òÄÔ∏è';
    });

    // PDF (simple, reliable)
    const pdfDownload = document.getElementById('pdfDownload');
    pdfDownload.addEventListener('click', () => {
      if (typeof html2pdf === 'undefined') {
        alert('PDF library is loading. Try again in a moment.');
        return;
      }
      document.body.classList.add('pdf-mode');
      const actions = document.querySelector('.topActions');
      if (actions) actions.style.display = 'none';

      const opt = {
        margin: 0.5,
        filename: 'VexTea_MichaelLazarek_Portfolio.pdf',
        image: { type: 'jpeg', quality: 0.98 },
        html2canvas: { scale: 2, useCORS: true },
        jsPDF: { unit: 'in', format: 'letter', orientation: 'portrait' },
        pagebreak: { mode: ['css', 'legacy'] }
      };

      html2pdf().from(document.body).set(opt).save().then(() => {
        document.body.classList.remove('pdf-mode');
        if (actions) actions.style.display = 'flex';
      }).catch(() => {
        document.body.classList.remove('pdf-mode');
        if (actions) actions.style.display = 'flex';
      });
    });
  </script>
</body>
</html>
